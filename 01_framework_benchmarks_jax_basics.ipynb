{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JGY6-z_1E71F",
        "USF7Ds8uDwNI"
      ],
      "gpuType": "V5E1",
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTtHxZT3VBULVc+fO9OX0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sineeli/jax_series/blob/main/01_framework_benchmarks_jax_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOU0mJai9lfV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import jax\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRNG Key in Torch, Tensorflow and JAX\n",
        "\n",
        "- In PyTorch and TensorFlow, setting a seed updates a global state hidden in the background. Every time you generate a random number, that global state is automatically mutated.\n",
        "- In **JAX** there is no global state which is getting mutated, instead you pass the key explicitly everytime and get the same number.\n",
        "- To get new random number you split/mutate the existing key and then generate again with new key.\n"
      ],
      "metadata": {
        "id": "JGY6-z_1E71F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Torch"
      ],
      "metadata": {
        "id": "y4t5vnt0DJ-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "print(torch.randn(1)) # Value A\n",
        "print(torch.randn(1)) # Value B (It remembers the state and generate new random numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srMFnhbb_Yxe",
        "outputId": "dc4de91a-70af-4d30-df94-3e611e40bf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367])\n",
            "tensor([0.1288])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow"
      ],
      "metadata": {
        "id": "qKrrsFHwDL3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "print(tf.random.normal([1])) # Value A\n",
        "print(tf.random.normal([1])) # Value B (It remembers the state and generate new random numbers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2sFtX53CFxB",
        "outputId": "2fd16004-2c86-4ee9-d362-bd2028597e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.3274685], shape=(1,), dtype=float32)\n",
            "tf.Tensor([0.08422458], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JAX"
      ],
      "metadata": {
        "id": "YhLryzlWDNiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.key(42)\n",
        "print(jax.random.normal(key)) # Value X\n",
        "print(jax.random.normal(key)) # Value X (Always the same!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ONpawqOCL6p",
        "outputId": "a19d6486-ba7f-4492-c26e-c8e99a3633f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.028304616\n",
            "-0.028304616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To generate new numbers here we need to split the key"
      ],
      "metadata": {
        "id": "USF7Ds8uDwNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the master key into two new keys\n",
        "key, subkey = jax.random.split(key)\n",
        "\n",
        "# Use the subkey for your random number\n",
        "print(jax.random.normal(subkey)) # Value Y (New!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1AbSnmbD8Vs",
        "outputId": "eeb3dea3-cdd2-4a37-cfb6-2d9c9da2315b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.60576403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now lets jump to comparing the speeds\n",
        "\n",
        "\n",
        "Notes:\n",
        "\n",
        "- JAX/TF: They are \"Greedy.\" They pre-allocate a fixed percentage (usually 75% for JAX) of the GPU memory at startup to optimize for speed and avoid the overhead of asking the OS for memory repeatedly.\n",
        "\n",
        "- PyTorch: It is \"Lazy.\" It allocates memory on-demand. This is why it feels \"lighter\" initially, but it can lead to fragmentation in long-running training jobs.\n"
      ],
      "metadata": {
        "id": "1wCE9qWzGEOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 3000"
      ],
      "metadata": {
        "id": "h1AaY9DcKE_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# avoids pre allocatin the GPU memory\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
        "\n",
        "# avoids pre allocatin the GPU memory\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpus[0], True)"
      ],
      "metadata": {
        "id": "2njidqyxQL3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.key(42)\n",
        "\n",
        "# lets put jax array in CPU because if we are using GPU it places array direclty in GPU\n",
        "cpus = jax.devices(\"cpu\")\n",
        "with jax.default_device(cpus[0]):\n",
        "    # This is created directly in RAM, GPU is never touched\n",
        "    x_jnp = jax.random.normal(key, (size, size))\n",
        "\n",
        "# same case with Tensorflow we need to mention where to place the data\n",
        "with tf.device('/CPU:0'):\n",
        "  x_tf = tf.random.normal((size, size))\n",
        "\n",
        "\n",
        "# torch doesn't do until you explicityly move to cuda device.\n",
        "x_torch = torch.randn(size, size)"
      ],
      "metadata": {
        "id": "Ffage_p3GCKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_jnp.device, x_tf.device, x_torch.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4TmL3RYOzbN",
        "outputId": "5b52c30a-bc8e-4d9b-8eda-25b5a4d57872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(CpuDevice(id=0),\n",
              " '/job:localhost/replica:0/task:0/device:CPU:0',\n",
              " device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CPU"
      ],
      "metadata": {
        "id": "rMiWtzO7OPD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### JAX\n",
        "\n",
        "- When you call `jnp.dot(x, y)`, JAX doesn't wait for the CPU/GPU to finish the math. Instead, it immediately returns a `DeviceArray` (a pointer to the future result)\n",
        "\n",
        "- `block_until_ready()` will wait till the execution completes so you can time it properly"
      ],
      "metadata": {
        "id": "fGSoKgHZOBwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jax.default_device(cpus[0]):\n",
        "  %time jax.numpy.dot(x_jnp, x_jnp.T) # this will show compilation time and then you can see the return value later"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUZSJOAbNGc4",
        "outputId": "1e46a135-b8ff-4895-dde5-077e6e5062c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 187 ms, sys: 16.6 ms, total: 204 ms\n",
            "Wall time: 130 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and lets the Python thread continue. The actual computation happens in the background on the accelerator.\n",
        "with jax.default_device(cpus[0]):\n",
        "  %timeit jax.numpy.dot(x_jnp, x_jnp.T).block_until_ready() # this will wait till the execution also completes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvRhymdDNfo0",
        "outputId": "d8d67e3b-cd54-4274-f67f-2a36afd8f0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "533 ms Â± 10.3 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow"
      ],
      "metadata": {
        "id": "km3YGzDZSqWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/CPU:0'):\n",
        "  %timeit tf.matmul(x_tf, x_tf) # here that is the not the case it executes eagerly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlcgEmt1KVQZ",
        "outputId": "366d6f1e-cc43-4713-fb6c-159165426876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599 ms Â± 96.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Torch"
      ],
      "metadata": {
        "id": "vCdT-_aWSs3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit torch.matmul(x_torch, x_torch) # here that is the not the case it executes eagerly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewdHmpQSKbou",
        "outputId": "b5ef89c5-8ad5-4d67-b379-3246b7ad6772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "685 ms Â± 298 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU\n",
        "*   **Inputs are Pre-Loaded on Device:**\n",
        "    The input arrays (`x_jnp`, `x_tf`, `x_torch`) are moved to the GPU memory (VRAM) *before* the timer starts. The overhead of moving data **to** the GPU is **excluded** from the benchmark.\n",
        "*   **Computation Happens on GPU:**\n",
        "    The matrix multiplication logic is executed entirely by the GPU cores.\n",
        "*   **Result is Transferred Back to Host (CPU):**\n",
        "    By calling `.numpy()` (TF/JAX) or `.cpu()` (PyTorch), you force the resulting tensor to be copied from GPU memory back to CPU RAM.\n",
        "*   **Implicit Synchronization:**\n",
        "    Because the CPU cannot access the data until the GPU is finished calculating and transferring it, this forces the CPU to wait. This ensures `%timeit` captures the full duration of the operation, effectively \"blocking\" the asynchronous nature of the GPU."
      ],
      "metadata": {
        "id": "e9V-0kXnS2vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_jnp = jax.random.normal(key, (size, size)) # sits in GPU by default\n",
        "x_tf = tf.random.normal((size, size)) # sits in GPU by default\n",
        "if torch.cuda.is_available():\n",
        "  x_torch = torch.randn(size, size).cuda() # sits in GPU"
      ],
      "metadata": {
        "id": "icZVXnWJTTAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### JAX"
      ],
      "metadata": {
        "id": "zht8svvVS8lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.array(jax.numpy.dot(x_jnp, x_jnp.T).block_until_ready())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UBzAcvRSxqv",
        "outputId": "551a0d3c-fba3-496d-93d7-1760df1d7f07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36.9 ms Â± 567 Âµs per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensorflow\n",
        "\n",
        "- Same as JAX, Tensorflow also dispatchs asynchornously so if you try directly timeit it will keep queueing not the math"
      ],
      "metadata": {
        "id": "ql5R2715TvTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit tf.matmul(x_tf, x_tf).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFDDyWRWTuV9",
        "outputId": "d622c3be-d6df-4624-9cfb-2a1e38c2c74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59.6 ms Â± 7.9 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Torch"
      ],
      "metadata": {
        "id": "5rSheggKTzm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit torch.matmul(x_torch, x_torch).cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWVeD8shT1rf",
        "outputId": "acf4827f-1ee4-4b02-9d23-31cdfd1de952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36.5 ms Â± 2.11 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TPU(Tensor Processing Units)\n",
        "\n",
        "- JAX Natively works on TPU.\n",
        "- TPU's are custom made chips from google to train ML models.\n",
        "- They are just built to calculate large matrix operations, here is the full [page](https://docs.cloud.google.com/tpu/docs/system-architecture-tpu-vm) to study.\n",
        "- We can run Tensorflow as well on TPU's but it needs a little bit of setup initially in colab."
      ],
      "metadata": {
        "id": "U7RprSgw9HWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "T5WrDHpS9igV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRXgSTusCcfE",
        "outputId": "47e5142c-f4ec-44fc-b105-ace147b89250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.key(42)\n",
        "size = 3000"
      ],
      "metadata": {
        "id": "Zc_RL2PaC5U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_jnp = jax.random.normal(key, (size, size)) # sits in TPU by default"
      ],
      "metadata": {
        "id": "8kLz1Jv5C0ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit np.array(jax.numpy.dot(x_jnp, x_jnp.T).block_until_ready()) # matrix is in on CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwJBAhffCqSN",
        "outputId": "92a7a08e-dabc-4bbf-859b-6d268757a3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.7 ms Â± 157 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit jax_dot(x_jnp).block_until_ready().device # the result is also in TPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdEyn1SlELnj",
        "outputId": "8022a46e-8db1-4159-8c12-56af45814430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "482 Âµs Â± 5.75 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More about JAX Now\n",
        "\n",
        "\n",
        "1. **JAX Arrays are immutable** - You cannot modify arrays in-place\n",
        "2. **Functional programming** - JAX relies on pure functions\n",
        "3. **Different random number generation** - Explicit key-based PRNG\n",
        "4. **Stateless** - State must be passed explicitly\n",
        "5. **Accelerator agnostic** - Same code runs on CPU, GPU, or TPU"
      ],
      "metadata": {
        "id": "DOwQZL6VHy7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selu(x, alpha=1.67, lmbda=1.05):\n",
        "  return lmbda * jax.numpy.where(x > 0, x, alpha * jax.numpy.exp(x) - alpha)"
      ],
      "metadata": {
        "id": "qxKx2WPgGw9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit selu(x_jnp).block_until_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nvq1n1WHNJz",
        "outputId": "e1a57714-4dc1-4de9-f839-374ecd438787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "972 Âµs Â± 6.38 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit jax.jit(selu)(x_jnp).block_until_ready() # JIT(Just in Time Compilation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQJEAQEvGygL",
        "outputId": "f20fe623-e548-4a13-9081-1627dc7da8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "389 Âµs Â± 9.96 Âµs per loop (mean Â± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How JIT Works: Tracing\n",
        "\n",
        "- JIT works by **tracing** your function. During tracing, JAX replaces actual values with abstract \"tracers\" that only track shapes and types:\n",
        "\n",
        "- **Key Insight:** Same shape + same type = reuse cached compiled function!\n"
      ],
      "metadata": {
        "id": "GQfRskxXIEBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def f(x, y):\n",
        "    print(\"Running f():\")\n",
        "    print(f\" x = {x}\")\n",
        "    print(f\" y = {y}\")\n",
        "    result = jax.numpy.dot(x + 1, y + 1)\n",
        "    print(f\" result = {result}\")\n",
        "    return result\n",
        "\n",
        "x = np.random.randn(3, 4)\n",
        "y = np.random.randn(4)"
      ],
      "metadata": {
        "id": "EBnPCm3pIDg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f(x, y)) # first call traces function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3VPYW1PIMSX",
        "outputId": "73a5e60c-cbd8-44e0-d6bc-1d23b2ac8bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running f():\n",
            " x = JitTracer<float32[3,4]>\n",
            " y = JitTracer<float32[4]>\n",
            " result = JitTracer<float32[3]>\n",
            "[8.396521  0.6653428 2.259801 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f(x, y)) # Second call - uses cached compiled version (no print!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7PxpY_iIQSf",
        "outputId": "bc43481b-0936-4f9e-9d77-4be962a1e598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.396521  0.6653428 2.259801 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing the JAX Expression (jaxpr)"
      ],
      "metadata": {
        "id": "LPzTuHWWIdnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x, y):\n",
        "    return jax.numpy.dot(x + 1, y + 1)\n",
        "\n",
        "print(jax.make_jaxpr(f)(x, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnTH6NK9IVlZ",
        "outputId": "80687cd7-7329-4697-ce3b-f30708278f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{ \u001b[34;1mlambda \u001b[39;22m; a\u001b[35m:f32[3,4]\u001b[39m b\u001b[35m:f32[4]\u001b[39m. \u001b[34;1mlet\n",
            "    \u001b[39;22mc\u001b[35m:f32[3,4]\u001b[39m = add a 1.0:f32[]\n",
            "    d\u001b[35m:f32[4]\u001b[39m = add b 1.0:f32[]\n",
            "    e\u001b[35m:f32[3]\u001b[39m = dot_general[\n",
            "      dimension_numbers=(([1], [0]), ([], []))\n",
            "      preferred_element_type=float32\n",
            "    ] c d\n",
            "  \u001b[34;1min \u001b[39;22m(e,) }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JIT Pitfalls\n",
        "\n",
        "- You can find full sharpbits in jax here more extensive: [ðŸ”ª sharpbits](https://docs.jax.dev/en/latest/notebooks/Common_Gotchas_in_JAX.html) which is much more extensive and if I miss something or made a mistake please correct me"
      ],
      "metadata": {
        "id": "Uy-8T5voI10A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  1. Dynamic Shapes\n",
        "- JIT requires **static shapes**. Boolean indexing creates dynamic shapes:\n",
        "- Basically you trying to change the output of the function dynamically based on the boolean value, so this causes the error in `jit` compilation."
      ],
      "metadata": {
        "id": "opf97jPUNBwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_negatives(x):\n",
        "    return x[x < 0]  # Shape depends on values!\n",
        "\n",
        "x = jax.random.normal(key, (10,))\n",
        "get_negatives(x)  # Works without JIT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pzGSbvDI2dH",
        "outputId": "bfa3842a-674b-4676-8163-3c8ad4ccd88f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Array([-0.02830462, -0.12403281, -1.4408795 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  jax.jit(get_negatives)(x)\n",
        "except Exception as NonConcreteBooleanIndexError:\n",
        "  print(NonConcreteBooleanIndexError)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joDm5Vf2IjTb",
        "outputId": "aec67585-e7c5-4cd5-ebe3-4f5c8e6c398d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array boolean indices must be concrete; got bool[10]\n",
            "\n",
            "See https://docs.jax.dev/en/latest/errors.html#jax.errors.NonConcreteBooleanIndexError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Value-Dependent Control Flow\n",
        "\n",
        "- Python tries to execute the if immediately during compilation (tracing).\n",
        "- It needs to know the value of neg right now to decide which branch to compile.\n",
        "- But neg is just a placeholder (a Tracer) that doesn't have a value yet.\n",
        "-Since Python can't decide, it crashes."
      ],
      "metadata": {
        "id": "zYvetwucNimX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def f(x, neg):\n",
        "    return -x if neg else x  # Control flow depends on VALUE\n",
        "\n",
        "f(1, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "jMkIY-AlNHd2",
        "outputId": "50e01d55-f199-4505-aea2-f69944bdb42b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TracerBoolConversionError",
          "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function f at /tmp/ipython-input-2759705761.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument neg.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2759705761.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# Control flow depends on VALUE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2759705761.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x, neg)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m  \u001b[0;31m# Control flow depends on VALUE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1804\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTracerBoolConversionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mfun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function f at /tmp/ipython-input-2759705761.py:1 for jit. This concrete value was not available in Python because it depends on the value of the argument neg.\nSee https://docs.jax.dev/en/latest/errors.html#jax.errors.TracerBoolConversionError"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can make use of `static_argnames` if that particular doesn't change in training and its not related to data batching flag."
      ],
      "metadata": {
        "id": "ZQCBQdWAwszR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "@partial(jit, static_argnames=['neg'])\n",
        "def f(x, neg=True):\n",
        "    return -x if neg else x  # Control flow depends on VALUE\n",
        "\n",
        "f(1, True)"
      ],
      "metadata": {
        "id": "lD5CsLmKwesn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Using JAX Arrays for Shapes\n",
        "\n",
        "- You converted the shape (2, 3) into a JAX array.\n",
        "- JAX treats all JAX arrays as \"values that will exist on the GPU later\" (Tracers).\n",
        "- reshape needs to know the exact size right now to allocate memory in the compiled graph. You gave it a \"future value\" placeholder, so the compiler panics because it can't build a graph with unknown dimensions."
      ],
      "metadata": {
        "id": "T0_R88QexLjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def f(x):\n",
        "    # BAD: jnp.array(x.shape) creates a traced value\n",
        "    return x.reshape(jnp.array(x.shape).prod())\n",
        "f(jnp.ones((2, 3)))  # ERROR!"
      ],
      "metadata": {
        "id": "SEyXrWFexLHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jit\n",
        "def f(x):\n",
        "    return x.reshape((np.prod(x.shape),))\n",
        "\n",
        "f(jnp.ones((2, 3)))  # Works!"
      ],
      "metadata": {
        "id": "d-FeCYvlyWPr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}